{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1k7cXviOacTA",
        "outputId": "ba80438a-6b91-4862-8d27-0aab4b94905f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cli.github.com/packages stable InRelease\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Connected to cloud.r-project.or\r                                                                               \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Waiting f\r                                                                               \rGet:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Waiting for headers] [3 InRelease 0 B/129 kB 0%] [Waiting for headers] [Wai\r                                                                               \rHit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:6 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,201 kB]\n",
            "Get:9 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:13 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ Packages [83.6 kB]\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,844 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,519 kB]\n",
            "Get:16 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [38.5 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,287 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [6,087 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,918 kB]\n",
            "Get:20 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,575 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [6,327 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,598 kB]\n",
            "Fetched 37.9 MB in 7s (5,339 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  dialign emboss-data emboss-lib fonts-lato libauthen-sasl-perl libclone-perl\n",
            "  libdata-dump-perl libencode-locale-perl libfile-listing-perl\n",
            "  libfont-afm-perl libhpdf-2.3.0 libhtml-form-perl libhtml-format-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhtml-tree-perl\n",
            "  libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl\n",
            "  libhttp-message-perl libhttp-negotiate-perl libio-html-perl\n",
            "  libio-socket-ssl-perl liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libruby3.0 libtry-tiny-perl liburi-perl libwww-perl libwww-robotrules-perl\n",
            "  lynx lynx-common ncbi-data netbase perl-openssl-defaults primer3 python3-all\n",
            "  rake ruby ruby-net-telnet ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0\n",
            "  rubygems-integration\n",
            "Suggested packages:\n",
            "  emboss-doc emboss-test embassy clustalw libdigest-hmac-perl libgssapi-perl\n",
            "  libcrypt-ssleay-perl libsub-name-perl libbusiness-isbn-perl\n",
            "  libauthen-ntlm-perl ncbi-epcr ri ruby-dev bundler\n",
            "Recommended packages:\n",
            "  blast2\n",
            "The following NEW packages will be installed:\n",
            "  dialign emboss emboss-data emboss-lib fonts-lato libauthen-sasl-perl\n",
            "  libclone-perl libdata-dump-perl libencode-locale-perl libfile-listing-perl\n",
            "  libfont-afm-perl libhpdf-2.3.0 libhtml-form-perl libhtml-format-perl\n",
            "  libhtml-parser-perl libhtml-tagset-perl libhtml-tree-perl\n",
            "  libhttp-cookies-perl libhttp-daemon-perl libhttp-date-perl\n",
            "  libhttp-message-perl libhttp-negotiate-perl libio-html-perl\n",
            "  libio-socket-ssl-perl liblwp-mediatypes-perl liblwp-protocol-https-perl\n",
            "  libmailtools-perl libnet-http-perl libnet-smtp-ssl-perl libnet-ssleay-perl\n",
            "  libruby3.0 libtry-tiny-perl liburi-perl libwww-perl libwww-robotrules-perl\n",
            "  lynx lynx-common mafft megahit ncbi-blast+ ncbi-data netbase\n",
            "  perl-openssl-defaults primer3 python3-all rake ruby ruby-net-telnet\n",
            "  ruby-rubygems ruby-webrick ruby-xmlrpc ruby3.0 rubygems-integration seqtk\n",
            "0 upgraded, 54 newly installed, 0 to remove and 72 not upgraded.\n",
            "Need to get 94.9 MB of archives.\n",
            "After this operation, 630 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 fonts-lato all 2.0-2.1 [2,696 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 netbase all 6.3 [12.9 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 dialign amd64 2.2.1-11 [139 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libhpdf-2.3.0 amd64 2.3.0+dfsg-1build1 [335 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 emboss-lib amd64 6.6.0+dfsg-11ubuntu1 [2,971 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 emboss-data all 6.6.0+dfsg-11ubuntu1 [61.0 MB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 emboss amd64 6.6.0+dfsg-11ubuntu1 [977 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libclone-perl amd64 0.45-1build3 [11.0 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libdata-dump-perl all 1.25-1 [25.9 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/main amd64 libencode-locale-perl all 1.05-1.1 [11.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-date-perl all 6.05-1 [9,920 B]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfile-listing-perl all 6.14-1 [11.2 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfont-afm-perl all 1.20-3 [13.6 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-tagset-perl all 3.20-4 [12.5 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 liburi-perl all 5.10-1 [78.8 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-parser-perl amd64 3.76-1build2 [88.4 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libio-html-perl all 1.004-2 [15.4 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblwp-mediatypes-perl all 6.04-1 [19.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-message-perl all 6.36-1 [76.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-form-perl all 6.07-1 [22.2 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-tree-perl all 5.07-2 [200 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhtml-format-perl all 2.12-1.1 [41.3 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-cookies-perl all 6.10-1 [18.4 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libhttp-daemon-perl all 6.13-1ubuntu0.1 [22.9 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libhttp-negotiate-perl all 6.01-1 [12.5 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 perl-openssl-defaults amd64 5build2 [7,542 B]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnet-ssleay-perl amd64 1.92-1build2 [327 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 libio-socket-ssl-perl all 2.074-2 [192 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnet-http-perl all 6.22-1 [23.2 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/main amd64 libtry-tiny-perl all 0.31-1 [21.8 kB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwww-robotrules-perl all 6.02-1 [12.6 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwww-perl all 6.61-1 [141 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/main amd64 liblwp-protocol-https-perl all 6.10-1 [10.9 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/main amd64 libnet-smtp-ssl-perl all 1.04-1 [5,948 B]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmailtools-perl all 2.21-1 [80.7 kB]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 rubygems-integration all 1.18 [5,336 B]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby3.0 amd64 3.0.2-7ubuntu2.11 [50.1 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-rubygems all 3.3.5-2ubuntu1.2 [228 kB]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby amd64 1:3.0~exp1 [5,100 B]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy/main amd64 rake all 13.0.6-2 [61.7 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy/main amd64 ruby-net-telnet all 0.1.1-2 [12.6 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-webrick all 1.7.0-3ubuntu0.2 [52.5 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 ruby-xmlrpc all 0.3.2-1ubuntu0.1 [24.9 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libruby3.0 amd64 3.0.2-7ubuntu2.11 [5,114 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lynx-common all 2.9.0dev.10-1 [1,024 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 mafft amd64 7.490-1 [776 kB]\n",
            "Get:47 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 python3-all amd64 3.10.6-1~22.04.1 [902 B]\n",
            "Get:48 http://archive.ubuntu.com/ubuntu jammy/universe amd64 megahit amd64 1.2.9-3 [1,042 kB]\n",
            "Get:49 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ncbi-data all 6.1.20170106+dfsg1-9 [3,519 kB]\n",
            "Get:50 http://archive.ubuntu.com/ubuntu jammy/universe amd64 ncbi-blast+ amd64 2.12.0+ds-3build1 [12.3 MB]\n",
            "Get:51 http://archive.ubuntu.com/ubuntu jammy/universe amd64 primer3 amd64 2.5.0-1 [208 kB]\n",
            "Get:52 http://archive.ubuntu.com/ubuntu jammy/universe amd64 seqtk amd64 1.3-2 [30.2 kB]\n",
            "Get:53 http://archive.ubuntu.com/ubuntu jammy/main amd64 libauthen-sasl-perl all 2.1600-1.1 [43.1 kB]\n",
            "Get:54 http://archive.ubuntu.com/ubuntu jammy/universe amd64 lynx amd64 2.9.0dev.10-1 [719 kB]\n",
            "Fetched 94.9 MB in 5s (19.7 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package fonts-lato.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../00-fonts-lato_2.0-2.1_all.deb ...\n",
            "Unpacking fonts-lato (2.0-2.1) ...\n",
            "Selecting previously unselected package netbase.\n",
            "Preparing to unpack .../01-netbase_6.3_all.deb ...\n",
            "Unpacking netbase (6.3) ...\n",
            "Selecting previously unselected package dialign.\n",
            "Preparing to unpack .../02-dialign_2.2.1-11_amd64.deb ...\n",
            "Unpacking dialign (2.2.1-11) ...\n",
            "Selecting previously unselected package libhpdf-2.3.0:amd64.\n",
            "Preparing to unpack .../03-libhpdf-2.3.0_2.3.0+dfsg-1build1_amd64.deb ...\n",
            "Unpacking libhpdf-2.3.0:amd64 (2.3.0+dfsg-1build1) ...\n",
            "Selecting previously unselected package emboss-lib.\n",
            "Preparing to unpack .../04-emboss-lib_6.6.0+dfsg-11ubuntu1_amd64.deb ...\n",
            "Unpacking emboss-lib (6.6.0+dfsg-11ubuntu1) ...\n",
            "Selecting previously unselected package emboss-data.\n",
            "Preparing to unpack .../05-emboss-data_6.6.0+dfsg-11ubuntu1_all.deb ...\n",
            "Unpacking emboss-data (6.6.0+dfsg-11ubuntu1) ...\n",
            "Selecting previously unselected package emboss.\n",
            "Preparing to unpack .../06-emboss_6.6.0+dfsg-11ubuntu1_amd64.deb ...\n",
            "Unpacking emboss (6.6.0+dfsg-11ubuntu1) ...\n",
            "Selecting previously unselected package libclone-perl.\n",
            "Preparing to unpack .../07-libclone-perl_0.45-1build3_amd64.deb ...\n",
            "Unpacking libclone-perl (0.45-1build3) ...\n",
            "Selecting previously unselected package libdata-dump-perl.\n",
            "Preparing to unpack .../08-libdata-dump-perl_1.25-1_all.deb ...\n",
            "Unpacking libdata-dump-perl (1.25-1) ...\n",
            "Selecting previously unselected package libencode-locale-perl.\n",
            "Preparing to unpack .../09-libencode-locale-perl_1.05-1.1_all.deb ...\n",
            "Unpacking libencode-locale-perl (1.05-1.1) ...\n",
            "Selecting previously unselected package libhttp-date-perl.\n",
            "Preparing to unpack .../10-libhttp-date-perl_6.05-1_all.deb ...\n",
            "Unpacking libhttp-date-perl (6.05-1) ...\n",
            "Selecting previously unselected package libfile-listing-perl.\n",
            "Preparing to unpack .../11-libfile-listing-perl_6.14-1_all.deb ...\n",
            "Unpacking libfile-listing-perl (6.14-1) ...\n",
            "Selecting previously unselected package libfont-afm-perl.\n",
            "Preparing to unpack .../12-libfont-afm-perl_1.20-3_all.deb ...\n",
            "Unpacking libfont-afm-perl (1.20-3) ...\n",
            "Selecting previously unselected package libhtml-tagset-perl.\n",
            "Preparing to unpack .../13-libhtml-tagset-perl_3.20-4_all.deb ...\n",
            "Unpacking libhtml-tagset-perl (3.20-4) ...\n",
            "Selecting previously unselected package liburi-perl.\n",
            "Preparing to unpack .../14-liburi-perl_5.10-1_all.deb ...\n",
            "Unpacking liburi-perl (5.10-1) ...\n",
            "Selecting previously unselected package libhtml-parser-perl:amd64.\n",
            "Preparing to unpack .../15-libhtml-parser-perl_3.76-1build2_amd64.deb ...\n",
            "Unpacking libhtml-parser-perl:amd64 (3.76-1build2) ...\n",
            "Selecting previously unselected package libio-html-perl.\n",
            "Preparing to unpack .../16-libio-html-perl_1.004-2_all.deb ...\n",
            "Unpacking libio-html-perl (1.004-2) ...\n",
            "Selecting previously unselected package liblwp-mediatypes-perl.\n",
            "Preparing to unpack .../17-liblwp-mediatypes-perl_6.04-1_all.deb ...\n",
            "Unpacking liblwp-mediatypes-perl (6.04-1) ...\n",
            "Selecting previously unselected package libhttp-message-perl.\n",
            "Preparing to unpack .../18-libhttp-message-perl_6.36-1_all.deb ...\n",
            "Unpacking libhttp-message-perl (6.36-1) ...\n",
            "Selecting previously unselected package libhtml-form-perl.\n",
            "Preparing to unpack .../19-libhtml-form-perl_6.07-1_all.deb ...\n",
            "Unpacking libhtml-form-perl (6.07-1) ...\n",
            "Selecting previously unselected package libhtml-tree-perl.\n",
            "Preparing to unpack .../20-libhtml-tree-perl_5.07-2_all.deb ...\n",
            "Unpacking libhtml-tree-perl (5.07-2) ...\n",
            "Selecting previously unselected package libhtml-format-perl.\n",
            "Preparing to unpack .../21-libhtml-format-perl_2.12-1.1_all.deb ...\n",
            "Unpacking libhtml-format-perl (2.12-1.1) ...\n",
            "Selecting previously unselected package libhttp-cookies-perl.\n",
            "Preparing to unpack .../22-libhttp-cookies-perl_6.10-1_all.deb ...\n",
            "Unpacking libhttp-cookies-perl (6.10-1) ...\n",
            "Selecting previously unselected package libhttp-daemon-perl.\n",
            "Preparing to unpack .../23-libhttp-daemon-perl_6.13-1ubuntu0.1_all.deb ...\n",
            "Unpacking libhttp-daemon-perl (6.13-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libhttp-negotiate-perl.\n",
            "Preparing to unpack .../24-libhttp-negotiate-perl_6.01-1_all.deb ...\n",
            "Unpacking libhttp-negotiate-perl (6.01-1) ...\n",
            "Selecting previously unselected package perl-openssl-defaults:amd64.\n",
            "Preparing to unpack .../25-perl-openssl-defaults_5build2_amd64.deb ...\n",
            "Unpacking perl-openssl-defaults:amd64 (5build2) ...\n",
            "Selecting previously unselected package libnet-ssleay-perl:amd64.\n",
            "Preparing to unpack .../26-libnet-ssleay-perl_1.92-1build2_amd64.deb ...\n",
            "Unpacking libnet-ssleay-perl:amd64 (1.92-1build2) ...\n",
            "Selecting previously unselected package libio-socket-ssl-perl.\n",
            "Preparing to unpack .../27-libio-socket-ssl-perl_2.074-2_all.deb ...\n",
            "Unpacking libio-socket-ssl-perl (2.074-2) ...\n",
            "Selecting previously unselected package libnet-http-perl.\n",
            "Preparing to unpack .../28-libnet-http-perl_6.22-1_all.deb ...\n",
            "Unpacking libnet-http-perl (6.22-1) ...\n",
            "Selecting previously unselected package libtry-tiny-perl.\n",
            "Preparing to unpack .../29-libtry-tiny-perl_0.31-1_all.deb ...\n",
            "Unpacking libtry-tiny-perl (0.31-1) ...\n",
            "Selecting previously unselected package libwww-robotrules-perl.\n",
            "Preparing to unpack .../30-libwww-robotrules-perl_6.02-1_all.deb ...\n",
            "Unpacking libwww-robotrules-perl (6.02-1) ...\n",
            "Selecting previously unselected package libwww-perl.\n",
            "Preparing to unpack .../31-libwww-perl_6.61-1_all.deb ...\n",
            "Unpacking libwww-perl (6.61-1) ...\n",
            "Selecting previously unselected package liblwp-protocol-https-perl.\n",
            "Preparing to unpack .../32-liblwp-protocol-https-perl_6.10-1_all.deb ...\n",
            "Unpacking liblwp-protocol-https-perl (6.10-1) ...\n",
            "Selecting previously unselected package libnet-smtp-ssl-perl.\n",
            "Preparing to unpack .../33-libnet-smtp-ssl-perl_1.04-1_all.deb ...\n",
            "Unpacking libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Selecting previously unselected package libmailtools-perl.\n",
            "Preparing to unpack .../34-libmailtools-perl_2.21-1_all.deb ...\n",
            "Unpacking libmailtools-perl (2.21-1) ...\n",
            "Selecting previously unselected package rubygems-integration.\n",
            "Preparing to unpack .../35-rubygems-integration_1.18_all.deb ...\n",
            "Unpacking rubygems-integration (1.18) ...\n",
            "Selecting previously unselected package ruby3.0.\n",
            "Preparing to unpack .../36-ruby3.0_3.0.2-7ubuntu2.11_amd64.deb ...\n",
            "Unpacking ruby3.0 (3.0.2-7ubuntu2.11) ...\n",
            "Selecting previously unselected package ruby-rubygems.\n",
            "Preparing to unpack .../37-ruby-rubygems_3.3.5-2ubuntu1.2_all.deb ...\n",
            "Unpacking ruby-rubygems (3.3.5-2ubuntu1.2) ...\n",
            "Selecting previously unselected package ruby.\n",
            "Preparing to unpack .../38-ruby_1%3a3.0~exp1_amd64.deb ...\n",
            "Unpacking ruby (1:3.0~exp1) ...\n",
            "Selecting previously unselected package rake.\n",
            "Preparing to unpack .../39-rake_13.0.6-2_all.deb ...\n",
            "Unpacking rake (13.0.6-2) ...\n",
            "Selecting previously unselected package ruby-net-telnet.\n",
            "Preparing to unpack .../40-ruby-net-telnet_0.1.1-2_all.deb ...\n",
            "Unpacking ruby-net-telnet (0.1.1-2) ...\n",
            "Selecting previously unselected package ruby-webrick.\n",
            "Preparing to unpack .../41-ruby-webrick_1.7.0-3ubuntu0.2_all.deb ...\n",
            "Unpacking ruby-webrick (1.7.0-3ubuntu0.2) ...\n",
            "Selecting previously unselected package ruby-xmlrpc.\n",
            "Preparing to unpack .../42-ruby-xmlrpc_0.3.2-1ubuntu0.1_all.deb ...\n",
            "Unpacking ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Selecting previously unselected package libruby3.0:amd64.\n",
            "Preparing to unpack .../43-libruby3.0_3.0.2-7ubuntu2.11_amd64.deb ...\n",
            "Unpacking libruby3.0:amd64 (3.0.2-7ubuntu2.11) ...\n",
            "Selecting previously unselected package lynx-common.\n",
            "Preparing to unpack .../44-lynx-common_2.9.0dev.10-1_all.deb ...\n",
            "Unpacking lynx-common (2.9.0dev.10-1) ...\n",
            "Selecting previously unselected package mafft.\n",
            "Preparing to unpack .../45-mafft_7.490-1_amd64.deb ...\n",
            "Unpacking mafft (7.490-1) ...\n",
            "Selecting previously unselected package python3-all.\n",
            "Preparing to unpack .../46-python3-all_3.10.6-1~22.04.1_amd64.deb ...\n",
            "Unpacking python3-all (3.10.6-1~22.04.1) ...\n",
            "Selecting previously unselected package megahit.\n",
            "Preparing to unpack .../47-megahit_1.2.9-3_amd64.deb ...\n",
            "Unpacking megahit (1.2.9-3) ...\n",
            "Selecting previously unselected package ncbi-data.\n",
            "Preparing to unpack .../48-ncbi-data_6.1.20170106+dfsg1-9_all.deb ...\n",
            "Unpacking ncbi-data (6.1.20170106+dfsg1-9) ...\n",
            "Selecting previously unselected package ncbi-blast+.\n",
            "Preparing to unpack .../49-ncbi-blast+_2.12.0+ds-3build1_amd64.deb ...\n",
            "Unpacking ncbi-blast+ (2.12.0+ds-3build1) ...\n",
            "Selecting previously unselected package primer3.\n",
            "Preparing to unpack .../50-primer3_2.5.0-1_amd64.deb ...\n",
            "Unpacking primer3 (2.5.0-1) ...\n",
            "Selecting previously unselected package seqtk.\n",
            "Preparing to unpack .../51-seqtk_1.3-2_amd64.deb ...\n",
            "Unpacking seqtk (1.3-2) ...\n",
            "Selecting previously unselected package libauthen-sasl-perl.\n",
            "Preparing to unpack .../52-libauthen-sasl-perl_2.1600-1.1_all.deb ...\n",
            "Unpacking libauthen-sasl-perl (2.1600-1.1) ...\n",
            "Selecting previously unselected package lynx.\n",
            "Preparing to unpack .../53-lynx_2.9.0dev.10-1_amd64.deb ...\n",
            "Unpacking lynx (2.9.0dev.10-1) ...\n",
            "Setting up ncbi-data (6.1.20170106+dfsg1-9) ...\n",
            "Setting up libhttp-date-perl (6.05-1) ...\n",
            "Setting up libhpdf-2.3.0:amd64 (2.3.0+dfsg-1build1) ...\n",
            "Setting up fonts-lato (2.0-2.1) ...\n",
            "Setting up libfile-listing-perl (6.14-1) ...\n",
            "Setting up seqtk (1.3-2) ...\n",
            "Setting up libfont-afm-perl (1.20-3) ...\n",
            "Setting up mafft (7.490-1) ...\n",
            "Setting up libclone-perl (0.45-1build3) ...\n",
            "Setting up libhtml-tagset-perl (3.20-4) ...\n",
            "Setting up libauthen-sasl-perl (2.1600-1.1) ...\n",
            "Setting up liblwp-mediatypes-perl (6.04-1) ...\n",
            "Setting up libtry-tiny-perl (0.31-1) ...\n",
            "Setting up perl-openssl-defaults:amd64 (5build2) ...\n",
            "Setting up python3-all (3.10.6-1~22.04.1) ...\n",
            "Setting up libencode-locale-perl (1.05-1.1) ...\n",
            "Setting up rubygems-integration (1.18) ...\n",
            "Setting up emboss-data (6.6.0+dfsg-11ubuntu1) ...\n",
            "Setting up ncbi-blast+ (2.12.0+ds-3build1) ...\n",
            "Setting up primer3 (2.5.0-1) ...\n",
            "Setting up libdata-dump-perl (1.25-1) ...\n",
            "Setting up ruby-net-telnet (0.1.1-2) ...\n",
            "Setting up libio-html-perl (1.004-2) ...\n",
            "Setting up lynx-common (2.9.0dev.10-1) ...\n",
            "Setting up ruby-webrick (1.7.0-3ubuntu0.2) ...\n",
            "Setting up megahit (1.2.9-3) ...\n",
            "Setting up netbase (6.3) ...\n",
            "Setting up emboss-lib (6.6.0+dfsg-11ubuntu1) ...\n",
            "Setting up lynx (2.9.0dev.10-1) ...\n",
            "update-alternatives: using /usr/bin/lynx to provide /usr/bin/www-browser (www-browser) in auto mode\n",
            "Setting up dialign (2.2.1-11) ...\n",
            "Setting up ruby-xmlrpc (0.3.2-1ubuntu0.1) ...\n",
            "Setting up liburi-perl (5.10-1) ...\n",
            "Setting up libhttp-message-perl (6.36-1) ...\n",
            "Setting up libnet-ssleay-perl:amd64 (1.92-1build2) ...\n",
            "Setting up libhttp-negotiate-perl (6.01-1) ...\n",
            "Setting up emboss (6.6.0+dfsg-11ubuntu1) ...\n",
            "Setting up libhttp-cookies-perl (6.10-1) ...\n",
            "Setting up libnet-http-perl (6.22-1) ...\n",
            "Setting up libwww-robotrules-perl (6.02-1) ...\n",
            "Setting up libhttp-daemon-perl (6.13-1ubuntu0.1) ...\n",
            "Setting up libhtml-parser-perl:amd64 (3.76-1build2) ...\n",
            "Setting up libio-socket-ssl-perl (2.074-2) ...\n",
            "Setting up libhtml-form-perl (6.07-1) ...\n",
            "Setting up libhtml-tree-perl (5.07-2) ...\n",
            "Setting up libhtml-format-perl (2.12-1.1) ...\n",
            "Setting up libnet-smtp-ssl-perl (1.04-1) ...\n",
            "Setting up libmailtools-perl (2.21-1) ...\n",
            "Setting up libwww-perl (6.61-1) ...\n",
            "Setting up ruby3.0 (3.0.2-7ubuntu2.11) ...\n",
            "Setting up liblwp-protocol-https-perl (6.10-1) ...\n",
            "Setting up ruby (1:3.0~exp1) ...\n",
            "Setting up rake (13.0.6-2) ...\n",
            "Setting up libruby3.0:amd64 (3.0.2-7ubuntu2.11) ...\n",
            "Setting up ruby-rubygems (3.3.5-2ubuntu1.2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for shared-mime-info (2.1-2) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#First, install all necessary packages:\n",
        "!apt-get update\n",
        "!apt-get install -y megahit ncbi-blast+ seqtk emboss mafft"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import compressed (zip) version of files, orelse it takes way too long; upload your highest coverage SRR\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "d85SH85Ab_Vp",
        "outputId": "fe1069ee-7083-4e80-90c3-5cfa572b471f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-584b587b-f350-41ab-9bb6-d3e9d4580e0c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-584b587b-f350-41ab-9bb6-d3e9d4580e0c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving all_contigs.fa.zip to all_contigs.fa.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip all_contigs.fa.zip #unzip my all_contigs file"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nwhtVKLk_2d",
        "outputId": "7d066909-31c6-4990-c8d1-d49a04cf8d18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  all_contigs.fa.zip\n",
            "  inflating: all_contigs.fa          \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh #check to see that our unzipped file exists"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fqU15CEcMVh",
        "outputId": "9cd4911b-ff4d-4ea3-f471-a0f33fca7f34"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 584M\n",
            "-rw-r--r-- 1 root root 456M Dec  8 15:27 all_contigs.fa\n",
            "-rw-r--r-- 1 root root 128M Dec 10 17:04 all_contigs.fa.zip\n",
            "drwxr-xr-x 1 root root 4.0K Nov 20 14:30 sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Run MEGAHIT assembly for contigs\n",
        "!mkdir -p /content/megahit_tmp  #temporary directory\n",
        "\n",
        "!megahit -r all_contigs.fa \\\n",
        "         -o /content/megahit_out \\\n",
        "         --min-contig-len 25 \\\n",
        "         --tmp-dir /content/megahit_tmp\n",
        "\n",
        "#Zip the output folder & download\n",
        "!zip -r megahit_out.zip megahit_out\n",
        "from google.colab import files\n",
        "files.download('megahit_out.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SseGwytYcM6Q",
        "outputId": "1c7c086c-4b4f-4624-ac65-7a5c632b65fd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-10 17:06:23 - MEGAHIT v1.2.9\n",
            "2025-12-10 17:06:23 - Using megahit_core with POPCNT and BMI2 support\n",
            "2025-12-10 17:06:23 - Convert reads to binary library\n",
            "2025-12-10 17:06:25 - b'INFO  ./src/sequence/io/sequence_lib.cpp:   75 - Lib 0 (/content/all_contigs.fa): se, 2347596 reads, 16590 max length'\n",
            "2025-12-10 17:06:25 - b'INFO  ./src/utils/utils.h           :  152 - Real: 2.7151\\tuser: 2.5671\\tsys: 0.3896\\tmaxrss: 166540'\n",
            "2025-12-10 17:06:25 - k-max reset to: 141 \n",
            "2025-12-10 17:06:25 - Start assembly. Number of CPU threads 2 \n",
            "2025-12-10 17:06:25 - k list: 21,29,39,59,79,99,119,141 \n",
            "2025-12-10 17:06:25 - Memory used: 12245258649\n",
            "2025-12-10 17:06:25 - Extract solid (k+1)-mers for k = 21 \n",
            "2025-12-10 17:08:19 - Build graph for k = 21 \n",
            "2025-12-10 17:10:46 - Assemble contigs from SdBG for k = 21\n",
            "2025-12-10 17:15:23 - Local assembly for k = 21\n",
            "2025-12-10 17:16:13 - Extract iterative edges from k = 21 to 29 \n",
            "2025-12-10 17:16:46 - Build graph for k = 29 \n",
            "2025-12-10 17:17:42 - Assemble contigs from SdBG for k = 29\n",
            "2025-12-10 17:21:11 - Local assembly for k = 29\n",
            "2025-12-10 17:21:53 - Extract iterative edges from k = 29 to 39 \n",
            "2025-12-10 17:22:12 - Build graph for k = 39 \n",
            "2025-12-10 17:22:53 - Assemble contigs from SdBG for k = 39\n",
            "2025-12-10 17:25:27 - Local assembly for k = 39\n",
            "2025-12-10 17:26:07 - Extract iterative edges from k = 39 to 59 \n",
            "2025-12-10 17:26:20 - Build graph for k = 59 \n",
            "2025-12-10 17:26:49 - Assemble contigs from SdBG for k = 59\n",
            "2025-12-10 17:29:03 - Local assembly for k = 59\n",
            "2025-12-10 17:29:41 - Extract iterative edges from k = 59 to 79 \n",
            "2025-12-10 17:29:51 - Build graph for k = 79 \n",
            "2025-12-10 17:30:15 - Assemble contigs from SdBG for k = 79\n",
            "2025-12-10 17:32:15 - Local assembly for k = 79\n",
            "2025-12-10 17:32:54 - Extract iterative edges from k = 79 to 99 \n",
            "2025-12-10 17:33:07 - Build graph for k = 99 \n",
            "2025-12-10 17:33:30 - Assemble contigs from SdBG for k = 99\n",
            "2025-12-10 17:35:13 - Local assembly for k = 99\n",
            "2025-12-10 17:35:52 - Extract iterative edges from k = 99 to 119 \n",
            "2025-12-10 17:36:05 - Build graph for k = 119 \n",
            "2025-12-10 17:36:26 - Assemble contigs from SdBG for k = 119\n",
            "2025-12-10 17:37:59 - Local assembly for k = 119\n",
            "2025-12-10 17:38:36 - Extract iterative edges from k = 119 to 141 \n",
            "2025-12-10 17:38:46 - Build graph for k = 141 \n",
            "2025-12-10 17:39:03 - Assemble contigs from SdBG for k = 141\n",
            "2025-12-10 17:40:12 - Merging to output final contigs \n",
            "2025-12-10 17:40:12 - 116514 contigs, total 47251527 bp, min 142 bp, max 17386 bp, avg 405 bp, N50 602 bp\n",
            "2025-12-10 17:40:12 - ALL DONE. Time elapsed: 2029.194697 seconds \n",
            "  adding: megahit_out/ (stored 0%)\n",
            "  adding: megahit_out/final.contigs.fa (deflated 72%)\n",
            "  adding: megahit_out/intermediate_contigs/ (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k59.bubble_seq.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k29.final.contigs.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k59.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k39.addi.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k99.bubble_seq.fa (deflated 74%)\n",
            "  adding: megahit_out/intermediate_contigs/k29.local.fa (deflated 73%)\n",
            "  adding: megahit_out/intermediate_contigs/k79.contigs.fa (deflated 73%)\n",
            "  adding: megahit_out/intermediate_contigs/k141.contigs.fa (deflated 72%)\n",
            "  adding: megahit_out/intermediate_contigs/k79.local.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k79.addi.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k141.final.contigs.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k39.local.fa (deflated 72%)\n",
            "  adding: megahit_out/intermediate_contigs/k99.addi.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k79.bubble_seq.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k99.final.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k99.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k29.local.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k119.addi.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k59.local.fa (deflated 72%)\n",
            "  adding: megahit_out/intermediate_contigs/k99.local.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k119.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k29.bubble_seq.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k141.bubble_seq.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k21.bubble_seq.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k119.bubble_seq.fa (deflated 73%)\n",
            "  adding: megahit_out/intermediate_contigs/k99.bubble_seq.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k99.addi.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k21.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k29.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k39.final.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k79.final.contigs.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k59.addi.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k119.bubble_seq.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k79.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k59.final.contigs.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k59.addi.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k39.contigs.fa (deflated 73%)\n",
            "  adding: megahit_out/intermediate_contigs/k119.final.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k79.addi.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k141.bubble_seq.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k21.local.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k79.bubble_seq.fa (deflated 73%)\n",
            "  adding: megahit_out/intermediate_contigs/k141.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k29.addi.fa (deflated 68%)\n",
            "  adding: megahit_out/intermediate_contigs/k21.final.contigs.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k119.final.contigs.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k39.bubble_seq.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k99.local.fa (deflated 72%)\n",
            "  adding: megahit_out/intermediate_contigs/k21.addi.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k99.contigs.fa (deflated 72%)\n",
            "  adding: megahit_out/intermediate_contigs/k21.contigs.fa (deflated 74%)\n",
            "  adding: megahit_out/intermediate_contigs/k21.bubble_seq.fa (deflated 76%)\n",
            "  adding: megahit_out/intermediate_contigs/k119.contigs.fa (deflated 72%)\n",
            "  adding: megahit_out/intermediate_contigs/k21.addi.fa (deflated 76%)\n",
            "  adding: megahit_out/intermediate_contigs/k119.local.fa (deflated 72%)\n",
            "  adding: megahit_out/intermediate_contigs/k141.addi.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k39.addi.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k119.addi.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k59.bubble_seq.fa (deflated 73%)\n",
            "  adding: megahit_out/intermediate_contigs/k99.final.contigs.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k29.final.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k59.contigs.fa (deflated 73%)\n",
            "  adding: megahit_out/intermediate_contigs/k39.bubble_seq.fa (deflated 74%)\n",
            "  adding: megahit_out/intermediate_contigs/k39.final.contigs.fa (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k21.local.fa (deflated 72%)\n",
            "  adding: megahit_out/intermediate_contigs/k79.local.fa (deflated 72%)\n",
            "  adding: megahit_out/intermediate_contigs/k141.final.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k119.local.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k39.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k141.addi.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k59.local.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k39.local.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k29.bubble_seq.fa (deflated 74%)\n",
            "  adding: megahit_out/intermediate_contigs/k79.final.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k21.final.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k29.addi.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k59.final.contigs.fa.info (stored 0%)\n",
            "  adding: megahit_out/intermediate_contigs/k29.contigs.fa (deflated 72%)\n",
            "  adding: megahit_out/log (deflated 89%)\n",
            "  adding: megahit_out/checkpoints.txt (deflated 70%)\n",
            "  adding: megahit_out/done (stored 0%)\n",
            "  adding: megahit_out/options.json (deflated 53%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4e33d6f3-708f-4dcb-99c3-7d173bdaafd0\", \"megahit_out.zip\", 183175334)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls megahit_out #check to see that our final.contigs.fa has been created"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hl3cIHFExpOm",
        "outputId": "0b5e34c7-fb3b-4d12-e019-09bbdb4b813a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoints.txt  final.contigs.fa      log\n",
            "done\t\t intermediate_contigs  options.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a new fasta file for my rdrp palm sequence\n",
        "with open(\"/content/palm.faa\", \"w\") as f:\n",
        "    f.write(\">rdrp_palm\\n\")\n",
        "    f.write(\"MMGVPQEDIQMVEFFWLGHKRLFVKGKFVGTMVNGIPMGDPLTKTCMSLAHAIAHLYAVYKVGAFGRNEGNGDDLTL\\n\")"
      ],
      "metadata": {
        "id": "nH4LAt_0yFIt"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create a nucleotide database from our MEGAHIT contigs to conduct our analysis\n",
        "!makeblastdb \\\n",
        "    -in /content/megahit_out/final.contigs.fa \\\n",
        "    -dbtype nucl \\\n",
        "    -out /content/contigs_db"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jQJzHYqT7KnZ",
        "outputId": "1cbafaf7-2d48-450f-fc3f-8b07d26e426a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Building a new DB, current time: 12/10/2025 17:44:05\n",
            "New DB name:   /content/contigs_db\n",
            "New DB title:  /content/megahit_out/final.contigs.fa\n",
            "Sequence type: Nucleotide\n",
            "Keep MBits: T\n",
            "Maximum file size: 1000000000B\n",
            "Adding sequences from FASTA; added 116514 sequences in 2.64559 seconds.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh /content/contigs_db* #Check contents\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FOsHBL97O6J",
        "outputId": "94996832-e098-4f2a-fcdf-0d9a72cb6516"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw-r--r-- 1 root root  20K Dec 10 17:44 /content/contigs_db.ndb\n",
            "-rw-r--r-- 1 root root  12M Dec 10 17:44 /content/contigs_db.nhr\n",
            "-rw-r--r-- 1 root root 1.4M Dec 10 17:44 /content/contigs_db.nin\n",
            "-rw-r--r-- 1 root root 1.4M Dec 10 17:44 /content/contigs_db.not\n",
            "-rw-r--r-- 1 root root  12M Dec 10 17:44 /content/contigs_db.nsq\n",
            "-rw-r--r-- 1 root root  16K Dec 10 17:44 /content/contigs_db.ntf\n",
            "-rw-r--r-- 1 root root 456K Dec 10 17:44 /content/contigs_db.nto\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally, tblastn! This can also be done on site, but I am keeping everything in this notebook for ease\n",
        "!tblastn -query /content/palm.faa \\\n",
        "         -db /content/contigs_db \\\n",
        "         -out /content/tblastn_results.txt \\\n",
        "         -evalue 1e-5 \\\n",
        "         -outfmt 6"
      ],
      "metadata": {
        "id": "RAdt_SiZ7lU1"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head /content/tblastn_results.txt #Check what contigs are hit!\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLx3Pxbu7vli",
        "outputId": "f1e552b6-94ac-4003-bda3-042700a98a61"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rdrp_palm\tk141_63250\t98.701\t77\t1\t0\t1\t77\t412\t182\t1.97e-53\t162\n",
            "rdrp_palm\tk141_70773\t100.000\t44\t0\t0\t6\t49\t1\t132\t4.49e-28\t95.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Open BLAST results to get matching contig IDs\n",
        "with open('/content/tblastn_results.txt', 'r') as f:\n",
        "  hits = f.readlines()\n",
        "  contig_ids = [hit.split()[1] for hit in hits]\n",
        "\n",
        "#Extract matching sequences only\n",
        "with open('/content/megahit_out/final.contigs.fa', 'r') as f:\n",
        "  contigs = f.read()\n",
        "\n",
        "#Finally, put only matching contigs into a new file\n",
        "with open('/content/filtered_contigs.fa', 'w') as f:\n",
        "    for contig_id in contig_ids:\n",
        "        start_index = contigs.find(f\">{contig_id}\")\n",
        "        if start_index != -1:\n",
        "            end_index = contigs.find(\">\", start_index + 1)\n",
        "            contig = contigs[start_index:end_index] if end_index != -1 else contigs[start_index:]\n",
        "            f.write(contig + \"\\n\")"
      ],
      "metadata": {
        "id": "2z8MYf-58AR8"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Download my rdrp!\n",
        "from google.colab import files\n",
        "files.download('/content/filtered_contigs.fa')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "a5LqxRRD8PwL",
        "outputId": "bb94d34e-4b4f-4e69-caf0-03c2917bb891"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1606532e-c6c9-42e2-b37d-de0417e6bf8d\", \"filtered_contigs.fa\", 640)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!head -n 10 /content/filtered_contigs.fa #check first 10 bases"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wN-jZdaX9noM",
        "outputId": "bfb56b40-69ba-4419-875e-7488002051ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "head: cannot open '/content/filtered_contigs.fa' for reading: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Next, blasgn to see if any other contigs align to our recovered rdrp contig to extend the genome\n",
        "!blastn -query /content/filtered_contigs.fa -db /content/megahit_out/final.contigs.fa -out /content/blastn_results.txt -evalue 1e-5 -outfmt 6"
      ],
      "metadata": {
        "id": "bpt3zXFK9hCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Extract contigs\n",
        "!grep -A 1 \">k141_24308\" /content/megahit_out/final.contigs.fa > /content/contig_k141_24308.fa\n",
        "!grep -A 1 \">k141_36662\" /content/megahit_out/final.contigs.fa > /content/contig_k141_36662.fa\n",
        "!grep -A 1 \">k141_40107\" /content/megahit_out/final.contigs.fa > /content/contig_k141_40107.fa\n"
      ],
      "metadata": {
        "id": "51JK-9BJ-k_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally, download. You now have all files needed for rdrp/genome assembly!\n",
        "from google.colab import files\n",
        "files.download('/content/contig_k141_24308.fa')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "G5WSmfkF-qkh",
        "outputId": "0e6a60e0-a9e5-457f-ef79-47b22709d077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4c5ae036-e7f6-4bb5-b020-335f9c34a3ba\", \"contig_k141_24308.fa\", 793)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_a55821ec-b46c-436d-9a94-cd963f8c4ecf\", \"contig_k141_36662.fa\", 374)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_0f0f9565-6337-4c68-979a-909dd75141db\", \"contig_k141_40107.fa\", 343)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}